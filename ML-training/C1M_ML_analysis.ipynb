{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle # to save and load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trades_df = pd.read_csv('buy_signals_backtest_ML_July-Aug2020.dat')\n",
    "trades_df = pd.read_csv('buy_signals_backtest_ML_Jan2019-Aug2020.dat')\n",
    "#trades_df.set_index('time_curr', inplace=True)\n",
    "#trades_df.index=pd.to_datetime(trades_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_curr', 'symbol', 'price', 'pattern', 'origin', 'ranging',\n",
       "       'd_ranging', 'lower', 'upper', 'middle', 'd_lower', 'd_upper',\n",
       "       'd_middle', 'ema_10', 'ema_200', 'd_ema_10', 'd_ema_200', 'k_15',\n",
       "       'd_15', 'd_k_15', 'd_d_15', 'stoch_cond_5', 'candle_color', 'vol_inc',\n",
       "       'dist_to_BB', 'profit', 'elapsed', 'min_price', 'max_price',\n",
       "       'profit_s15', 'elapsed_s15', 'min_price_s15', 'max_price_s15',\n",
       "       'Unnamed: 33'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitability = [0 if item < 0 else 1 for item in trades_df['profit']]\n",
    "trades_df['profitability'] = profitability\n",
    "profitability_s15 = [0 if item < 0 else 1 for item in trades_df['profit_s15']]\n",
    "trades_df['profitability_s15'] = profitability_s15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert 'time_curr' to `datetime` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df['time_curr'] = pd.to_datetime(trades_df['time_curr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by the date:\n",
    "trades_df.sort_values(by=['time_curr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_curr', 'symbol', 'price', 'pattern', 'origin', 'ranging',\n",
       "       'd_ranging', 'lower', 'upper', 'middle', 'd_lower', 'd_upper',\n",
       "       'd_middle', 'ema_10', 'ema_200', 'd_ema_10', 'd_ema_200', 'k_15',\n",
       "       'd_15', 'd_k_15', 'd_d_15', 'stoch_cond_5', 'candle_color', 'vol_inc',\n",
       "       'dist_to_BB', 'profit', 'elapsed', 'min_price', 'max_price',\n",
       "       'profit_s15', 'elapsed_s15', 'min_price_s15', 'max_price_s15',\n",
       "       'Unnamed: 33', 'profitability', 'profitability_s15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total profitability in 617 days 10:45:00:  0.6138994161630646\n",
      "total n trades:  39052\n",
      "Total profitability in 617 days 10:45:00 with 0.15 stop loss:  0.4338318139916009\n",
      "total n trades:  39052\n"
     ]
    }
   ],
   "source": [
    "time_span = trades_df.time_curr.iloc[-1] - trades_df.time_curr.iloc[0]\n",
    "print(f\"Total profitability in {time_span}: \", trades_df['profitability'].sum()/len(trades_df['profitability']) )\n",
    "print(\"total n trades: \", len(trades_df['profitability']))\n",
    "print(f\"Total profitability in {time_span} with 0.15 stop loss: \", trades_df['profitability_s15'].sum()/len(trades_df['profitability_s15']) )\n",
    "print(\"total n trades: \", len(trades_df['profitability_s15']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df.drop(['Unnamed: 33'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23015    1\n",
       "23016    1\n",
       "23017    1\n",
       "14973    0\n",
       "22340    1\n",
       "        ..\n",
       "9339     1\n",
       "9340     1\n",
       "2661     1\n",
       "10106    1\n",
       "3250     1\n",
       "Name: profitability, Length: 39052, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades_df['profitability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trades_df.dropna(axis=1, inplace=True)\n",
    "trades_df.fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df = trades_df[trades_df.d_ema_200 != -9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the problematic coin that has been identified later\n",
    "#trades_df = trades_df[trades_df.symbol != 'UMABTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>ranging</th>\n",
       "      <th>d_ranging</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>middle</th>\n",
       "      <th>d_lower</th>\n",
       "      <th>d_upper</th>\n",
       "      <th>d_middle</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>ema_200</th>\n",
       "      <th>d_ema_10</th>\n",
       "      <th>d_ema_200</th>\n",
       "      <th>k_15</th>\n",
       "      <th>d_15</th>\n",
       "      <th>d_k_15</th>\n",
       "      <th>d_d_15</th>\n",
       "      <th>vol_inc</th>\n",
       "      <th>dist_to_BB</th>\n",
       "      <th>profit</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>profit_s15</th>\n",
       "      <th>elapsed_s15</th>\n",
       "      <th>min_price_s15</th>\n",
       "      <th>max_price_s15</th>\n",
       "      <th>profitability</th>\n",
       "      <th>profitability_s15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>3.867300e+04</td>\n",
       "      <td>3.867300e+04</td>\n",
       "      <td>3.867300e+04</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>3.867300e+04</td>\n",
       "      <td>3.867300e+04</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "      <td>38673.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>8.132035</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>-6.956378e-08</td>\n",
       "      <td>5.781294e-09</td>\n",
       "      <td>-3.160784e-08</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>-5.806764e-08</td>\n",
       "      <td>-4.493574e-09</td>\n",
       "      <td>17.991926</td>\n",
       "      <td>11.614167</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.267060</td>\n",
       "      <td>1.315766</td>\n",
       "      <td>3.156596</td>\n",
       "      <td>-0.236328</td>\n",
       "      <td>152.000776</td>\n",
       "      <td>-1.483952</td>\n",
       "      <td>1.519735</td>\n",
       "      <td>-0.198006</td>\n",
       "      <td>75.169265</td>\n",
       "      <td>-0.916117</td>\n",
       "      <td>1.194247</td>\n",
       "      <td>0.614149</td>\n",
       "      <td>0.433998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>4.929595</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>3.697506e-07</td>\n",
       "      <td>1.564281e-07</td>\n",
       "      <td>1.482744e-07</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>2.523498e-07</td>\n",
       "      <td>4.049922e-08</td>\n",
       "      <td>6.259305</td>\n",
       "      <td>5.698897</td>\n",
       "      <td>0.269057</td>\n",
       "      <td>0.162142</td>\n",
       "      <td>5.187358</td>\n",
       "      <td>2.017446</td>\n",
       "      <td>2.190608</td>\n",
       "      <td>277.567596</td>\n",
       "      <td>0.980151</td>\n",
       "      <td>1.295275</td>\n",
       "      <td>1.486893</td>\n",
       "      <td>140.239091</td>\n",
       "      <td>0.458446</td>\n",
       "      <td>1.180594</td>\n",
       "      <td>0.486802</td>\n",
       "      <td>0.495631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.393000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-1.039000e-05</td>\n",
       "      <td>-6.480000e-06</td>\n",
       "      <td>-3.520000e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-6.850000e-06</td>\n",
       "      <td>-9.500000e-07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-4.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5.227000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-3.000000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>12.220000</td>\n",
       "      <td>6.940000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>6.748000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-1.000000e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>10.620000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>2.579000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>-1.590000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>9.356000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>23.290000</td>\n",
       "      <td>15.410000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>3.652000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>-0.530000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>307.999000</td>\n",
       "      <td>3.898000</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.009661</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>9.100000e-06</td>\n",
       "      <td>7.020000e-06</td>\n",
       "      <td>2.630000e-06</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>1.160000e-06</td>\n",
       "      <td>9.800000e-07</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>673.619000</td>\n",
       "      <td>121.406000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>12083.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>36.020000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4617.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>33.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price       ranging     d_ranging         lower         upper  \\\n",
       "count  38673.000000  38673.000000  38673.000000  38673.000000  38673.000000   \n",
       "mean       0.000259      8.132035      0.015274      0.000257      0.000275   \n",
       "std        0.000901      4.929595      0.052520      0.000895      0.000954   \n",
       "min        0.000002      4.000000     -1.393000      0.000001      0.000002   \n",
       "25%        0.000007      5.227000      0.000000      0.000007      0.000007   \n",
       "50%        0.000030      6.748000      0.015000      0.000029      0.000032   \n",
       "75%        0.000124      9.356000      0.032000      0.000123      0.000131   \n",
       "max        0.008987    307.999000      3.898000      0.008979      0.009661   \n",
       "\n",
       "             middle       d_lower       d_upper      d_middle        ema_10  \\\n",
       "count  38673.000000  3.867300e+04  3.867300e+04  3.867300e+04  38673.000000   \n",
       "mean       0.000266 -6.956378e-08  5.781294e-09 -3.160784e-08      0.000262   \n",
       "std        0.000924  3.697506e-07  1.564281e-07  1.482744e-07      0.000912   \n",
       "min        0.000002 -1.039000e-05 -6.480000e-06 -3.520000e-06      0.000002   \n",
       "25%        0.000007 -3.000000e-08  0.000000e+00 -1.000000e-08      0.000007   \n",
       "50%        0.000030 -1.000000e-08  0.000000e+00 -0.000000e+00      0.000030   \n",
       "75%        0.000127  0.000000e+00 -0.000000e+00 -0.000000e+00      0.000125   \n",
       "max        0.009236  9.100000e-06  7.020000e-06  2.630000e-06      0.009112   \n",
       "\n",
       "            ema_200      d_ema_10     d_ema_200          k_15          d_15  \\\n",
       "count  38673.000000  3.867300e+04  3.867300e+04  38673.000000  38673.000000   \n",
       "mean       0.000265 -5.806764e-08 -4.493574e-09     17.991926     11.614167   \n",
       "std        0.000928  2.523498e-07  4.049922e-08      6.259305      5.698897   \n",
       "min        0.000001 -6.850000e-06 -9.500000e-07     10.000000      3.330000   \n",
       "25%        0.000007 -2.000000e-08  0.000000e+00     12.220000      6.940000   \n",
       "50%        0.000030 -0.000000e+00  0.000000e+00     16.730000     10.620000   \n",
       "75%        0.000126 -0.000000e+00  0.000000e+00     23.290000     15.410000   \n",
       "max        0.009531  1.160000e-06  9.800000e-07     30.000000     29.900000   \n",
       "\n",
       "             d_k_15        d_d_15       vol_inc    dist_to_BB        profit  \\\n",
       "count  38673.000000  38673.000000  38673.000000  38673.000000  38673.000000   \n",
       "mean       0.505600      0.267060      1.315766      3.156596     -0.236328   \n",
       "std        0.269057      0.162142      5.187358      2.017446      2.190608   \n",
       "min        0.000000      0.000000      0.000000      1.500000     -3.000000   \n",
       "25%        0.310000      0.150000      0.289000      1.955000     -3.000000   \n",
       "50%        0.490000      0.250000      0.681000      2.579000      1.500000   \n",
       "75%        0.690000      0.370000      1.353000      3.652000      1.500000   \n",
       "max        2.000000      0.670000    673.619000    121.406000      1.500000   \n",
       "\n",
       "            elapsed     min_price     max_price    profit_s15   elapsed_s15  \\\n",
       "count  38673.000000  38673.000000  38673.000000  38673.000000  38673.000000   \n",
       "mean     152.000776     -1.483952      1.519735     -0.198006     75.169265   \n",
       "std      277.567596      0.980151      1.295275      1.486893    140.239091   \n",
       "min        1.000000     -2.500000     -4.500000     -1.500000      1.000000   \n",
       "25%       24.000000     -2.500000      0.640000     -1.500000     12.000000   \n",
       "50%       64.000000     -1.590000      1.550000     -1.500000     32.000000   \n",
       "75%      162.000000     -0.500000      1.960000      1.500000     80.000000   \n",
       "max    12083.000000      0.880000     36.020000      1.500000   4617.000000   \n",
       "\n",
       "       min_price_s15  max_price_s15  profitability  profitability_s15  \n",
       "count   38673.000000   38673.000000   38673.000000       38673.000000  \n",
       "mean       -0.916117       1.194247       0.614149           0.433998  \n",
       "std         0.458446       1.180594       0.486802           0.495631  \n",
       "min        -1.250000      -4.460000       0.000000           0.000000  \n",
       "25%        -1.250000       0.320000       0.000000           0.000000  \n",
       "50%        -1.250000       1.040000       1.000000           0.000000  \n",
       "75%        -0.530000       1.740000       1.000000           1.000000  \n",
       "max         0.880000      33.920000       1.000000           1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trades_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we start preparing the dataset to train a model using various Machine Learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trades_df.drop(['symbol','profit',\n",
    "                    'stoch_cond_5','vol_inc',\n",
    "       'elapsed', 'min_price', 'max_price', 'profit_s15', 'elapsed_s15',\n",
    "       'min_price_s15', 'max_price_s15',  'profitability',\n",
    "       'profitability_s15'], axis=1)\n",
    "\n",
    "# For the 1st trial, let us also drop all categorical variables:\n",
    "# X = trades_df.drop(['time_curr','profit',\n",
    "#                     'pattern','origin','symbol','stoch_cond_5','candle_color',\n",
    "#        'elapsed', 'min_price', 'max_price', 'profit_s15', 'elapsed_s15',\n",
    "#        'min_price_s15', 'max_price_s15',  'profitability',\n",
    "#        'profitability_s15'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['stoch_cond_5'] = X['stoch_cond_5'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looks like features from timestamps don't help\n",
    "# X['day'] = X.time_curr.dt.day.astype('uint8')\n",
    "# X['hour'] = X.time_curr.dt.hour.astype('uint8')\n",
    "# X['minute'] = X.time_curr.dt.minute.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['time_curr'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'pattern', 'origin', 'ranging', 'd_ranging', 'lower', 'upper',\n",
       "       'middle', 'd_lower', 'd_upper', 'd_middle', 'ema_10', 'ema_200',\n",
       "       'd_ema_10', 'd_ema_200', 'k_15', 'd_15', 'd_k_15', 'd_d_15',\n",
       "       'candle_color', 'dist_to_BB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to drop all prices and keep only the slopes and percentages: (No!)\n",
    "## X = X.drop(['price', 'lower', 'upper', 'middle', 'ema_10'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['d_lower', 'd_upper', 'd_middle', 'd_ema_10', 'd_ema_200' ]: X[col] = X[col]*100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>pattern</th>\n",
       "      <th>origin</th>\n",
       "      <th>ranging</th>\n",
       "      <th>d_ranging</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>middle</th>\n",
       "      <th>d_lower</th>\n",
       "      <th>d_upper</th>\n",
       "      <th>d_middle</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>ema_200</th>\n",
       "      <th>d_ema_10</th>\n",
       "      <th>d_ema_200</th>\n",
       "      <th>k_15</th>\n",
       "      <th>d_15</th>\n",
       "      <th>d_k_15</th>\n",
       "      <th>d_d_15</th>\n",
       "      <th>candle_color</th>\n",
       "      <th>dist_to_BB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30297</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>no</td>\n",
       "      <td>upper</td>\n",
       "      <td>7.312</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.18</td>\n",
       "      <td>16.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.43</td>\n",
       "      <td>green</td>\n",
       "      <td>1.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22022</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>no</td>\n",
       "      <td>upper</td>\n",
       "      <td>9.851</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.95</td>\n",
       "      <td>10.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.24</td>\n",
       "      <td>red</td>\n",
       "      <td>6.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22023</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>lower</td>\n",
       "      <td>13.827</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.69</td>\n",
       "      <td>7.72</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>green</td>\n",
       "      <td>4.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22344</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>Harami</td>\n",
       "      <td>lower</td>\n",
       "      <td>6.464</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.00</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.04</td>\n",
       "      <td>green</td>\n",
       "      <td>2.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22346</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>no</td>\n",
       "      <td>lower</td>\n",
       "      <td>6.569</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19.36</td>\n",
       "      <td>17.33</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>red</td>\n",
       "      <td>2.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price pattern origin  ranging  d_ranging     lower     upper  \\\n",
       "30297  0.000013      no  upper    7.312      0.019  0.000012  0.000013   \n",
       "22022  0.000076      no  upper    9.851     -0.153  0.000072  0.000081   \n",
       "22023  0.000072  Hammer  lower   13.827      0.062  0.000071  0.000080   \n",
       "22344  0.000013  Harami  lower    6.464      0.026  0.000013  0.000014   \n",
       "22346  0.000013      no  lower    6.569      0.007  0.000013  0.000014   \n",
       "\n",
       "         middle  d_lower  d_upper  d_middle    ema_10   ema_200  d_ema_10  \\\n",
       "30297  0.000013    0.000    0.000     0.000  0.000013  0.000012     0.000   \n",
       "22022  0.000076    0.006   -0.003     0.002  0.000076  0.000065    -0.001   \n",
       "22023  0.000075   -0.003   -0.001    -0.002  0.000073  0.000066    -0.002   \n",
       "22344  0.000013   -0.000   -0.000    -0.000  0.000013  0.000012    -0.000   \n",
       "22346  0.000013   -0.000   -0.000    -0.000  0.000013  0.000012    -0.000   \n",
       "\n",
       "       d_ema_200   k_15   d_15  d_k_15  d_d_15 candle_color  dist_to_BB  \n",
       "30297      0.000  27.18  16.80    0.85    0.43        green       1.928  \n",
       "22022      0.001  10.95  10.45    0.05    0.24          red       6.454  \n",
       "22023      0.000  12.69   7.72    0.35    0.28        green       4.254  \n",
       "22344      0.000  21.00  14.84    0.41    0.04        green       2.795  \n",
       "22346      0.000  19.36  17.33    0.10    0.24          red       2.470  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Target:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we predict whether the trade is going to be profitable or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trades_df.profitability_s15\n",
    "# what if we predict profitability for stop loss 0.3?\n",
    "#y = trades_df.profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30297    0\n",
       "22022    0\n",
       "22023    0\n",
       "22344    1\n",
       "22346    1\n",
       "        ..\n",
       "9339     1\n",
       "9340     1\n",
       "2661     1\n",
       "10106    1\n",
       "3250     1\n",
       "Name: profitability_s15, Length: 38673, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_size = 2000\n",
    "\n",
    "# Make sure that there are no new symbols in the test dataset\n",
    "\n",
    "# for item_val in X.symbol.tail(test_size).unique():\n",
    "#     if item_val not in X.symbol.iloc[:-test_size].unique(): print(item_val)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[X.symbol != 'UMABTC']\n",
    "# y = y[X.symbol != 'UMABTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for item_val in X.symbol.tail(test_size).unique():\n",
    "#     if item_val not in X.symbol.iloc[:-test_size].unique(): print(item_val)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random split\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "\n",
    "# More realistic split is where we choose the latest deals as test data. Remove last rows:\n",
    "test_size = 2000\n",
    "# Remove last rows from the dataset\n",
    "X_train, y_train = X.iloc[:-test_size], y.iloc[:-test_size]\n",
    "X_val, y_val = X.tail(test_size), y.tail(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now it's time to make cathegorical encodings (or wait, let's do it later!) :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['pattern', 'origin', 'stoch_cond_5', 'candle_color']\n",
    "# label = ['symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in label:\n",
    "#     X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "#     X_val[col] = label_encoder.transform(X_val[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now go with the simplest One-Hot encoding provided by pandas:\n",
    "X_train, X_val = pd.get_dummies(X_train), pd.get_dummies(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val = preprocessing.scale(X_train), preprocessing.scale(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>ranging</th>\n",
       "      <th>d_ranging</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>middle</th>\n",
       "      <th>d_lower</th>\n",
       "      <th>d_upper</th>\n",
       "      <th>d_middle</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>ema_200</th>\n",
       "      <th>d_ema_10</th>\n",
       "      <th>d_ema_200</th>\n",
       "      <th>k_15</th>\n",
       "      <th>d_15</th>\n",
       "      <th>d_k_15</th>\n",
       "      <th>d_d_15</th>\n",
       "      <th>dist_to_BB</th>\n",
       "      <th>pattern_Bullish eng.</th>\n",
       "      <th>pattern_Doji</th>\n",
       "      <th>pattern_Hammer</th>\n",
       "      <th>pattern_Harami</th>\n",
       "      <th>pattern_no</th>\n",
       "      <th>origin_lower</th>\n",
       "      <th>origin_upper</th>\n",
       "      <th>candle_color_green</th>\n",
       "      <th>candle_color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30297</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>7.312</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.18</td>\n",
       "      <td>16.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22022</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>9.851</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.95</td>\n",
       "      <td>10.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22023</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>13.827</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.69</td>\n",
       "      <td>7.72</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22344</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6.464</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.00</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22346</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6.569</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19.36</td>\n",
       "      <td>17.33</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2471</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>7.814</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.77</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9596</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>5.502</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26.45</td>\n",
       "      <td>21.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2473</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>11.116</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.90</td>\n",
       "      <td>5.09</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4.186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2474</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10.969</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.64</td>\n",
       "      <td>12.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9542</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>4.394</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>27.77</td>\n",
       "      <td>14.69</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36673 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  ranging  d_ranging     lower     upper    middle  d_lower  \\\n",
       "30297  0.000013    7.312      0.019  0.000012  0.000013  0.000013    0.000   \n",
       "22022  0.000076    9.851     -0.153  0.000072  0.000081  0.000076    0.006   \n",
       "22023  0.000072   13.827      0.062  0.000071  0.000080  0.000075   -0.003   \n",
       "22344  0.000013    6.464      0.026  0.000013  0.000014  0.000013   -0.000   \n",
       "22346  0.000013    6.569      0.007  0.000013  0.000014  0.000013   -0.000   \n",
       "...         ...      ...        ...       ...       ...       ...      ...   \n",
       "2471   0.000004    7.814     -0.020  0.000004  0.000005  0.000004   -0.000   \n",
       "9596   0.000709    5.502     -0.008  0.000689  0.000727  0.000708    0.004   \n",
       "2473   0.000004   11.116      0.041  0.000004  0.000005  0.000004   -0.000   \n",
       "2474   0.000004   10.969     -0.010  0.000004  0.000005  0.000004   -0.000   \n",
       "9542   0.000047    4.394     -0.026  0.000047  0.000049  0.000048   -0.000   \n",
       "\n",
       "       d_upper  d_middle    ema_10   ema_200  d_ema_10  d_ema_200   k_15  \\\n",
       "30297    0.000     0.000  0.000013  0.000012     0.000      0.000  27.18   \n",
       "22022   -0.003     0.002  0.000076  0.000065    -0.001      0.001  10.95   \n",
       "22023   -0.001    -0.002  0.000073  0.000066    -0.002      0.000  12.69   \n",
       "22344   -0.000    -0.000  0.000013  0.000012    -0.000      0.000  21.00   \n",
       "22346   -0.000    -0.000  0.000013  0.000012    -0.000      0.000  19.36   \n",
       "...        ...       ...       ...       ...       ...        ...    ...   \n",
       "2471    -0.000    -0.000  0.000004  0.000003    -0.000      0.000  13.77   \n",
       "9596    -0.000     0.002  0.000708  0.000700    -0.003      0.000  26.45   \n",
       "2473     0.000    -0.000  0.000004  0.000003    -0.000      0.000  10.90   \n",
       "2474     0.000    -0.000  0.000004  0.000003    -0.000      0.000  20.64   \n",
       "9542    -0.000    -0.000  0.000048  0.000050    -0.000     -0.000  27.77   \n",
       "\n",
       "        d_15  d_k_15  d_d_15  dist_to_BB  pattern_Bullish eng.  pattern_Doji  \\\n",
       "30297  16.80    0.85    0.43       1.928                     0             0   \n",
       "22022  10.45    0.05    0.24       6.454                     0             0   \n",
       "22023   7.72    0.35    0.28       4.254                     0             0   \n",
       "22344  14.84    0.41    0.04       2.795                     0             0   \n",
       "22346  17.33    0.10    0.24       2.470                     0             0   \n",
       "...      ...     ...     ...         ...                   ...           ...   \n",
       "2471    7.38    0.64    0.31       2.021                     0             0   \n",
       "9596   21.19    0.33    0.44       2.519                     0             0   \n",
       "2473    5.09    0.44    0.15       4.186                     0             0   \n",
       "2474   12.32    0.58    0.46       3.521                     0             0   \n",
       "9542   14.69    0.83    0.52       1.514                     0             0   \n",
       "\n",
       "       pattern_Hammer  pattern_Harami  pattern_no  origin_lower  origin_upper  \\\n",
       "30297               0               0           1             0             1   \n",
       "22022               0               0           1             0             1   \n",
       "22023               1               0           0             1             0   \n",
       "22344               0               1           0             1             0   \n",
       "22346               0               0           1             1             0   \n",
       "...               ...             ...         ...           ...           ...   \n",
       "2471                0               0           1             1             0   \n",
       "9596                0               0           1             0             1   \n",
       "2473                0               1           0             1             0   \n",
       "2474                0               1           0             1             0   \n",
       "9542                0               0           1             1             0   \n",
       "\n",
       "       candle_color_green  candle_color_red  \n",
       "30297                   1                 0  \n",
       "22022                   0                 1  \n",
       "22023                   1                 0  \n",
       "22344                   1                 0  \n",
       "22346                   0                 1  \n",
       "...                   ...               ...  \n",
       "2471                    0                 1  \n",
       "9596                    0                 1  \n",
       "2473                    1                 0  \n",
       "2474                    1                 0  \n",
       "9542                    1                 0  \n",
       "\n",
       "[36673 rows x 27 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to compare different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for comparing different approaches\n",
    "def score_dataset(model, X_train, X_val, y_train, y_val, **kwargs):\n",
    "    '''Trains a model, makes predictions. \n",
    "    Prints classification report\n",
    "    Returns mean absolute error'''\n",
    "    #Modified from: https://www.kaggle.com/alexisbcook/exercise-categorical-variables\n",
    "    model.fit(X_train, y_train, **kwargs)\n",
    "    preds = model.predict(X_val)\n",
    "    print(classification_report(y_val,preds))\n",
    "    return mean_absolute_error(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's already try some methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_basic = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.86      0.73      1183\n",
      "           1       0.60      0.31      0.41       817\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.62      0.58      0.57      2000\n",
      "weighted avg       0.62      0.63      0.60      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.368"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Random Forest :\")\n",
    "score_dataset(random_forest_basic, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel_basic = LogisticRegression(solver='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taras\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.76      1183\n",
      "           1       0.67      0.32      0.43       817\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.66      0.60      0.59      2000\n",
      "weighted avg       0.66      0.66      0.62      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3425"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Logistic regression :\")\n",
    "score_dataset(logmodel_basic, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taras\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel_basic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = logmodel_basic.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.xticks(np.arange(len(importance)), X_val.columns, rotation=60)\n",
    "plt.ylim([-0.5,0.5])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different solvers for logostic regression\n",
    "# solvers = {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}\n",
    "# for solver in solvers:\n",
    "#     logmodel_solv = LogisticRegression(solver=solver)\n",
    "#     print(f\"Solver : {solver}\")\n",
    "#     score_dataset(logmodel_solv, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_basic = XGBClassifier(n_estimators=1000, learning_rate=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB_basic.fit(X_train, y_train,\n",
    "#              early_stopping_rounds=5, \n",
    "#              eval_set=[(X_val, y_val)], \n",
    "#              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      1183\n",
      "           1       0.60      0.57      0.59       817\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.66      0.65      0.65      2000\n",
      "weighted avg       0.67      0.67      0.67      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.332"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"XG Boost :\")\n",
    "score_dataset(XGB_basic, X_train, X_val, y_train, y_val,\n",
    "             early_stopping_rounds=10,\n",
    "             eval_set=[(X_val, y_val)],\n",
    "             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_preds_XGB = XGB_basic.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mae = mean_absolute_error(val_preds_XGB, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"MAE for the XG Boost without categorical features: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best model\n",
    "\n",
    "According to the classification reports, the best model that predicts succesfull trasdes is happened to be logistic regression.\n",
    "Now, save this model using `pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taras\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's train the model again:\n",
    "logmodel_basic = LogisticRegression(solver='warn')\n",
    "logmodel_basic.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model:\n",
    "with open('logregression.pickle', 'wb') as f:\n",
    "    pickle.dump(logmodel_basic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pre-trained model:\n",
    "pickle_in = open('logregression.pickle', 'rb')\n",
    "logmodel_loaded = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taras\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.76      1183\n",
      "           1       0.67      0.32      0.43       817\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.66      0.60      0.59      2000\n",
      "weighted avg       0.66      0.66      0.62      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3425"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if loaded model shows the same results:\n",
    "score_dataset(logmodel_loaded, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note. </b> `XGBoost` shows better accuracy in general, but it better predicts loosing trades rather than succesfull. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.2510e-05 2.6836e+01 2.5900e-01 1.0610e-05 1.3050e-05 1.1830e-05\n 1.0000e-03 0.0000e+00 0.0000e+00 1.2120e-05 9.8000e-06 0.0000e+00\n 0.0000e+00 1.8050e+01 1.1040e+01 6.5000e-01 1.8000e-01 4.3010e+00\n 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00\n 1.0000e+00 1.0000e+00 0.0000e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ec544382e5a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogmodel_loaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    263\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.2510e-05 2.6836e+01 2.5900e-01 1.0610e-05 1.3050e-05 1.1830e-05\n 1.0000e-03 0.0000e+00 0.0000e+00 1.2120e-05 9.8000e-06 0.0000e+00\n 0.0000e+00 1.8050e+01 1.1040e+01 6.5000e-01 1.8000e-01 4.3010e+00\n 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00\n 1.0000e+00 1.0000e+00 0.0000e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "logmodel_loaded.predict(X_val.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel_loaded.predict( np.array(X_val.iloc[-1]).reshape(1, -1) )[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                    0.000013\n",
       "ranging                 26.836000\n",
       "d_ranging                0.259000\n",
       "lower                    0.000011\n",
       "upper                    0.000013\n",
       "middle                   0.000012\n",
       "d_lower                  0.001000\n",
       "d_upper                  0.000000\n",
       "d_middle                 0.000000\n",
       "ema_10                   0.000012\n",
       "ema_200                  0.000010\n",
       "d_ema_10                 0.000000\n",
       "d_ema_200                0.000000\n",
       "k_15                    18.050000\n",
       "d_15                    11.040000\n",
       "d_k_15                   0.650000\n",
       "d_d_15                   0.180000\n",
       "dist_to_BB               4.301000\n",
       "pattern_Bullish eng.     0.000000\n",
       "pattern_Doji             0.000000\n",
       "pattern_Hammer           0.000000\n",
       "pattern_Harami           0.000000\n",
       "pattern_no               1.000000\n",
       "origin_lower             0.000000\n",
       "origin_upper             1.000000\n",
       "candle_color_green       1.000000\n",
       "candle_color_red         0.000000\n",
       "Name: 3250, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0 for _ in range(27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
